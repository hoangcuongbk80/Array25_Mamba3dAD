\section{Introduction}
\label{sec:introduction}

In modern manufacturing lines, even minute surface defects can propagate into catastrophic failures, ranging from microscopic cracks in aerospace components to subtle deformations in precision-molded parts, inflicting millions of dollars in recall costs and endangering human lives \cite{hoang2025unsupervised, feng2025hyperbolic, egodawela2025metal, hoang2025vistogeo}. Traditional two-dimensional inspection systems, though widespread, often miss these fine-scale anomalies when they occur on complex geometries or under variable lighting, leaving critical vulnerabilities undetected \cite{tong2025dam, hoang2025image, zhang2025unsupervised, song2025rstd}.

Recent advances in unsupervised image-based anomaly detection have achieved remarkable accuracy by modeling normal appearance patterns and flagging deviations via reconstruction errors or pretrained feature embeddings \cite{bergmann2020uninformed, shi2021dfr, roth2022towards}. However, these methods are fundamentally constrained by their two-dimensional nature. Occlusions or specular highlights can obscure defects, and critical geometric cues are lost in projection, so surface irregularities that alter only the third dimension may evade detection altogether. Point cloud anomaly detection addresses these limitations by directly capturing the full three-dimensional shape of inspected objects. Early registration pipelines using handcrafted descriptors established the viability of 3D methods \cite{horwitz2023back}. Subsequent unsupervised frameworks have applied student-teacher distillation to local 3D descriptors \cite{bergmann2023anomaly}, constructed memory banks of dual features \cite{liu2023real3d}, and exploited group-level feature alignment \cite{zhu2024towards}. Iterative reconstruction frameworks such as IMRNet \cite{li2024towards} and diffusion-based restorers like R3D-AD \cite{zhou2024r3d} have further enhanced localization accuracy. These approaches, however, often incur substantial memory or computational cost, rely on synthetic negatives that may not reflect real defect diversity, and can struggle to generalize across varied geometries and sensor noise patterns.

To address these challenges, we introduce a lightweight, single-pass framework that directly tackles three key obstacles in 3D anomaly detection: ambiguity in interpreting local geometric deviations without global context, distributional shifts between pretrained features and noisy industrial scans, and the scarcity of diverse defect examples needed for training robust detectors. Our approach builds on a Masked Autoencoder pretrained on ShapeNet and incorporates three innovative modules. First, a Spatial Context Aggregation mechanism uses optimal-transport-based prototype matching to anchor local patch features within a learned global shape context, reducing false positives arising from normal geometric variation. Second, a compact two-layer multilayer perceptron (MLP) serves as a Feature Adaptor, refining generic Point-MAE embeddings to align with the distinct statistics of industrial scans, thereby mitigating domain mismatch with minimal computational overhead. Third, to simulate a broad spectrum of potential anomalies without relying on manually labeled defects, our Selective Anomalous Feature Generator injects scaled Gaussian noise into random subsets of adapted feature tokens, producing realistic hard negatives in feature space. A lightweight attention-based discriminator, trained under patch-wise binary cross-entropy, learns to discriminate these synthetic anomalies from authentic defect-free patterns. We evaluate our framework on two complementary datasets. Real3D-AD \cite{liu2023real3d} provides ultra-high-precision scans of twelve object classes with carefully annotated bulges and sinks, serving as a controlled benchmark. Our newly released Industrial3D-AD dataset captures ten diverse real-world parts under actual factory conditions, complete with sensor quantization noise, partial occlusions, and subtle surface imperfections. Across both datasets, our method achieves state-of-the-art point- and object-level AUROC and AUPR, while maintaining real-time throughput above 13 frames per second, demonstrating both improved detection performance and practical deployment readiness.

In summary, our contributions are:
\begin{itemize}
\item A unified, single-pass 3D anomaly detection framework that integrates Spatial Context Aggregation, Feature Adaptor, and a selective Anomalous Feature Generator with an attention-based discriminator.
\item Spatial Context Aggregation, a parameter-free module that fuses local geometric neighborhoods with global prototypes via optimal transport to sharpen fine-scale defect cues.
\item A lightweight Feature Adaptor that fine-tunes pretrained Masked Autoencoder features to industrial domains, aligning feature distributions with minimal computational cost.
\item Anomaly synthesis and detection via selective feature-space corruption and a cross-patch attention discriminator trained with patch-wise binary supervision.
\item Comprehensive evaluation on Real3D-AD and Industrial3D-AD\footnote{Code and dataset: \url{https://github.com/hoangcuongbk80/industrial-3d-ad}} demonstrating state-of-the-art point- and object-level AUROC/AUPR and over 13 FPS inference speed.
\end{itemize}
